# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-zAuuZKOFmC6Tui5RczfoTKPHj9vEiV
"""

import tensorflow_hub as hub
import tensorflow as tf
hub_layer = hub.KerasLayer("https://tfhub.dev/google/nnlm-id-dim50/2", output_shape=[50],
                           input_shape=[], dtype=tf.string)

from tensorflow.keras.utils import to_categorical
from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation
from keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, SimpleRNN
from keras.models import Model
from keras.models import Sequential
from keras import initializers, regularizers, constraints, optimizers, layers
from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization
from keras.layers import Conv1D, MaxPooling1D, Embedding
from keras.models import Sequential

def build_model(hub_module, name):
    model = Sequential([
    hub_module])
    return model

model_nlm_v1 = build_model(hub_layer, 'modelV1')

model_nlm_v1.save('../resources/saved_model/text_query_v1')

import numpy as np
import pandas as pd
import tensorflow_recommenders as tfrs
import tensorflow as tf
from typing import Dict, Text

from tensorflow import feature_column
from tensorflow.keras import layers

import pathlib
import os


user_dataframe = pd.read_csv("../resources/Data/Combined Data.csv")
caregiver_dataframe = pd.read_csv("resources/Data/Processed Caregiver Data.csv")

unique_masalah_user = np.unique(' '.join(user_dataframe['Tipe_Masalah']).split(' '))
unique_masalah_caregiver = np.unique(' '.join(user_dataframe['Caregiver_Tipe_Masalah']).split(' '))
np.delete(unique_masalah_caregiver, np.where(unique_masalah_caregiver == ''))
unique_masalah_caregiver = np.delete(unique_masalah_caregiver, 0)

unique_masalah_caregiver = unique_masalah_caregiver.tolist()

for index, col in enumerate(unique_masalah_caregiver):
        unique_masalah_caregiver[index] = 'Caregiver-'+col

def convert_categorical_data(df, col='Tipe_Masalah'):
    ### Join every string in every row, split the result, pull out the unique values.
    genres = np.unique(' '.join(df[col]).split(' '))
    ### Drop 'NA'
    genres = np.delete(genres, np.where(genres == ''))
    if(col=='Tipe_Masalah'):
        for genre in genres:
            df[genre] = df[col].str.contains(genre).astype('int')
    else:
        for genre in genres:
            df['Caregiver-'+genre] = df[col].str.contains(genre).astype('int')
    df.drop(col, axis=1, inplace=True)

convert_categorical_data(user_dataframe)
convert_categorical_data(user_dataframe, col='Caregiver_Tipe_Masalah')
convert_categorical_data(caregiver_dataframe, col='Caregiver_Tipe_Masalah')


user_dataframe.drop(["USER_ID"], 1,inplace=True)
user_dataframe.drop(["CAREGIVER_ID"], 1,inplace=True)

user_dataframe.head()

caregiver_dataframe.head()

# A utility method to create a tf.data dataset from a Pandas Dataframe
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

batch_size = 5# A small batch sized is used for demonstration purposes
caregiver_ds = df_to_dataset(caregiver_dataframe, batch_size=batch_size,  shuffle=False)
user_ds = df_to_dataset(user_dataframe, batch_size=batch_size)

feature_columns = []

number_feature = ["Age"]
number_feature += unique_masalah_user.tolist()
print(unique_masalah_caregiver)
# numeric cols
for header in number_feature:
    feature_columns.append(feature_column.numeric_column(header))

age_feature = ["Age"]
for col in age_feature:
    age = feature_column.numeric_column(col)
    age_buckets = feature_column.bucketized_column(age, boundaries=[17, 21, 25, 29, 33, 37, 41, 46])
    feature_columns.append(age_buckets)

# indicator_columns
indicator_column_names = ['Gender']
for col_name in indicator_column_names:
  categorical_column = feature_column.categorical_column_with_vocabulary_list(
      col_name, user_dataframe[col_name].unique())
  indicator_column = feature_column.indicator_column(categorical_column)
  feature_columns.append(indicator_column)

for col in feature_columns:
    print(col)

feature_layer_user= tf.keras.layers.DenseFeatures(feature_columns)

feature_columns = []

number_feature = ["Caregiver_Age"]
number_feature += unique_masalah_caregiver
print(unique_masalah_caregiver)
# numeric cols

for header in number_feature:
    feature_columns.append(feature_column.numeric_column(header))

age_feature = ["Caregiver_Age"]
for col in age_feature:
    age = feature_column.numeric_column(col)
    age_buckets = feature_column.bucketized_column(age, boundaries=[17, 21, 25, 29, 33, 37, 41, 46])
    feature_columns.append(age_buckets)

col_name = 'Caregiver_Gender'
categorical_column = feature_column.categorical_column_with_vocabulary_list(
      col_name, user_dataframe[col_name].unique())
indicator_column = feature_column.indicator_column(categorical_column)
feature_columns.append(indicator_column)

feature_layer_caregiver= tf.keras.layers.DenseFeatures(feature_columns)

class RecomendModel(tfrs.Model):

  def __init__(self):
    super().__init__()

    embedding_dimension = 32

    # Set up a model for representing users.
    self.user_model = tf.keras.Sequential([
        feature_layer_user,
        layers.Dense(64),
        layers.Dense(32)
    ])

    # Set up a model for representing caregiver.
    self.caregiver_model = tf.keras.Sequential([
        feature_layer_caregiver,
        layers.Dense(64),
        layers.Dense(32)
    ])

    # Set up a task to optimize the model and compute metrics.
    self.task = tfrs.tasks.Retrieval(
      metrics=tfrs.metrics.FactorizedTopK(
        candidates=caregiver_ds.batch(5).map(self.caregiver_model)
      )
    )

  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:
    
    caregiver_features = ['Caregiver_Gender', 'Caregiver_Age',  'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']
    user_features = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']
    
    
    # We pick out the user features and pass them into the user model.
    
    print("AAAAAAAAAAAAAAAAAA")
    user_embeddings = self.user_model({
        'Age':features['Age'],
        'Gender':features['Gender'],
        'ADHD-Hiperaktif-dan-kurang-fokus':features['ADHD-Hiperaktif-dan-kurang-fokus'],
        'Depresi':features['Depresi'],
        'Gangguan-kecemasan':features['Gangguan-kecemasan'],
        'Gangguan-makan':features['Gangguan-makan'],
        'Gangguan-stres-pascatrauma':features['Gangguan-stres-pascatrauma'],
        'Skizofrenia':features['Skizofrenia']
    })
    print("BBBBBBBBBBBBBB")
    # And pick out the movie features and pass them into the movie model,
    # getting embeddings back.
    positive_movie_embeddings = self.caregiver_model({
        'Caregiver_Age':features['Caregiver_Age'],
        'Caregiver_Gender':features['Caregiver_Gender'],
        'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus':features['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus'],
        'Caregiver-Depresi':features['Caregiver-Depresi'],
        'Caregiver-Gangguan-kecemasan':features['Caregiver-Gangguan-kecemasan'],
        'Caregiver-Gangguan-makan':features['Caregiver-Gangguan-makan'],
        'Caregiver-Gangguan-stres-pascatrauma':features['Caregiver-Gangguan-stres-pascatrauma'],
        'Caregiver-Skizofrenia':features['Caregiver-Skizofrenia']
        
    })
    

    # The task computes the loss and the metrics.

    return self.task(user_embeddings, positive_movie_embeddings, compute_metrics=not training)

caregiver_features = ['Caregiver_Gender', 'Caregiver_Age',  'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']
user_features = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']

for feature_batch in caregiver_ds.take(1):
  print('Every feature:', list(feature_batch.keys()))
  print('A batch of ages:', feature_batch['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus'])

model = RecomendModel()

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])


model.user_model.save('../resources/saved_model/user_query_v1')
model.caregiver_model.load_weights('../resources/saved_model/caregiver_query_v1')

MAIN_USER_MODEL =   tf.keras.models.load_model('saved_model/user_query_v1')
MAIN_CAREGIVER_MODEL =  tf.keras.models.load_model('saved_model/caregiver_query_v1')

