# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-zAuuZKOFmC6Tui5RczfoTKPHj9vEiV
"""

import tensorflow as tf
import tensorflow_hub as hub
from keras import initializers, regularizers, constraints, optimizers, layers
from keras.models import Sequential


hub_layer = hub.KerasLayer("https://tfhub.dev/google/nnlm-id-dim50/2", output_shape=[50],
                           input_shape=[], dtype=tf.string)
def build_model(hub_module, name):
    model = Sequential([
    hub_module])
    return model

model_nlm_v1 = build_model(hub_layer, 'modelV1')


import numpy as np
import pandas as pd
import tensorflow_recommenders as tfrs
from typing import Dict, Text
from tensorflow import feature_column

import pathlib
import os

user_dataframe = pd.read_csv("../resources/Data/Combined Data.csv")
caregiver_dataframe = pd.read_csv("../resources/Data/Processed Caregiver Data.csv")

unique_masalah_user = np.unique(' '.join(user_dataframe['Tipe_Masalah']).split(' '))
unique_masalah_caregiver = np.unique(' '.join(user_dataframe['Caregiver_Tipe_Masalah']).split(' '))
np.delete(unique_masalah_caregiver, np.where(unique_masalah_caregiver == ''))
unique_masalah_caregiver = np.delete(unique_masalah_caregiver, 0)

unique_masalah_caregiver = unique_masalah_caregiver.tolist()

for index, col in enumerate(unique_masalah_caregiver):
        unique_masalah_caregiver[index] = 'Caregiver-'+col

def convert_categorical_data(df, col='Tipe_Masalah'):
    ### Join every string in every row, split the result, pull out the unique values.
    genres = np.unique(' '.join(df[col]).split(' '))
    ### Drop 'NA'
    genres = np.delete(genres, np.where(genres == ''))
    if(col=='Tipe_Masalah'):
        for genre in genres:
            df[genre] = df[col].str.contains(genre).astype('int')
    else:
        for genre in genres:
            df['Caregiver-'+genre] = df[col].str.contains(genre).astype('int')
    df.drop(col, axis=1, inplace=True)

convert_categorical_data(user_dataframe)
convert_categorical_data(user_dataframe, col='Caregiver_Tipe_Masalah')
convert_categorical_data(caregiver_dataframe, col='Caregiver_Tipe_Masalah')


user_dataframe.drop(["USER_ID"], axis=1,inplace=True)
user_dataframe.drop(["CAREGIVER_ID"], axis=1,inplace=True)

user_dataframe.head()

caregiver_dataframe.head()

# A utility method to create a tf.data dataset from a Pandas Dataframe
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

batch_size = 5# A small batch sized is used for demonstration purposes
caregiver_ds = df_to_dataset(caregiver_dataframe, batch_size=batch_size,  shuffle=False)
user_ds = df_to_dataset(user_dataframe, batch_size=batch_size)

feature_columns = []

number_feature = ["Age"]
number_feature += unique_masalah_user.tolist()
# numeric cols
for header in number_feature:
    feature_columns.append(feature_column.numeric_column(header))

age_feature = ["Age"]
for col in age_feature:
    age = feature_column.numeric_column(col)
    age_buckets = feature_column.bucketized_column(age, boundaries=[17, 21, 25, 29, 33, 37, 41, 46])
    feature_columns.append(age_buckets)

# indicator_columns
indicator_column_names = ['Gender']
for col_name in indicator_column_names:
  categorical_column = feature_column.categorical_column_with_vocabulary_list(
      col_name, user_dataframe[col_name].unique())
  indicator_column = feature_column.indicator_column(categorical_column)
  feature_columns.append(indicator_column)



feature_layer_user= tf.keras.layers.DenseFeatures(feature_columns)

feature_columns = []

number_feature = ["Caregiver_Age"]
number_feature += unique_masalah_caregiver
# numeric cols

for header in number_feature:
    feature_columns.append(feature_column.numeric_column(header))

age_feature = ["Caregiver_Age"]
for col in age_feature:
    age = feature_column.numeric_column(col)
    age_buckets = feature_column.bucketized_column(age, boundaries=[17, 21, 25, 29, 33, 37, 41, 46])
    feature_columns.append(age_buckets)

col_name = 'Caregiver_Gender'
categorical_column = feature_column.categorical_column_with_vocabulary_list(
      col_name, user_dataframe[col_name].unique())
indicator_column = feature_column.indicator_column(categorical_column)
feature_columns.append(indicator_column)

feature_layer_caregiver= tf.keras.layers.DenseFeatures(feature_columns)

class RecomendModel(tfrs.Model):

  def __init__(self):
    super().__init__()

    embedding_dimension = 32

    # Set up a model for representing users.
    self.user_model = tf.keras.Sequential([
        feature_layer_user,
        layers.Dense(64),
        layers.Dense(32, activation="linear")
    ])

    # Set up a model for representing caregiver.
    self.caregiver_model = tf.keras.Sequential([
        feature_layer_caregiver,
        layers.Dense(64),
        layers.Dense(32, activation="linear")
    ])

    # Set up a task to optimize the model and compute metrics.
    self.task = tfrs.tasks.Retrieval(
      metrics=tfrs.metrics.FactorizedTopK(
        candidates=caregiver_ds.batch(5).map(self.caregiver_model)
      )
    )

  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:
    
    caregiver_features = ['Caregiver_Gender', 'Caregiver_Age',  'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']
    user_features = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']
    
    
    # We pick out the user features and pass them into the user model.

    user_embeddings = self.user_model({
        'Age':features['Age'],
        'Gender':features['Gender'],
        'ADHD-Hiperaktif-dan-kurang-fokus':features['ADHD-Hiperaktif-dan-kurang-fokus'],
        'Depresi':features['Depresi'],
        'Gangguan-kecemasan':features['Gangguan-kecemasan'],
        'Gangguan-makan':features['Gangguan-makan'],
        'Gangguan-stres-pascatrauma':features['Gangguan-stres-pascatrauma'],
        'Skizofrenia':features['Skizofrenia']
    })
    # And pick out the movie features and pass them into the movie model,
    # getting embeddings back.
    positive_caregiver_embeddings = self.caregiver_model({
        'Caregiver_Age':features['Caregiver_Age'],
        'Caregiver_Gender':features['Caregiver_Gender'],
        'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus':features['Caregiver-ADHD-Hiperaktif-dan-kurang-fokus'],
        'Caregiver-Depresi':features['Caregiver-Depresi'],
        'Caregiver-Gangguan-kecemasan':features['Caregiver-Gangguan-kecemasan'],
        'Caregiver-Gangguan-makan':features['Caregiver-Gangguan-makan'],
        'Caregiver-Gangguan-stres-pascatrauma':features['Caregiver-Gangguan-stres-pascatrauma'],
        'Caregiver-Skizofrenia':features['Caregiver-Skizofrenia']
        
    })
    

    # The task computes the loss and the metrics.

    return self.task(user_embeddings, positive_caregiver_embeddings, compute_metrics=not training)

caregiver_features = ['Caregiver_Gender', 'Caregiver_Age',  'Caregiver-ADHD-Hiperaktif-dan-kurang-fokus', 'Caregiver-Depresi', 'Caregiver-Gangguan-kecemasan', 'Caregiver-Gangguan-makan', 'Caregiver-Gangguan-stres-pascatrauma', 'Caregiver-Skizofrenia']
user_features = ['Gender', 'Age', 'ADHD-Hiperaktif-dan-kurang-fokus', 'Depresi', 'Gangguan-kecemasan', 'Gangguan-makan','Gangguan-stres-pascatrauma', 'Skizofrenia']

model = RecomendModel()
model.load_weights("../resources/Recommender_Weights/")

def return_model():
    return [model_nlm_v1,model.user_model,model.caregiver_model]

